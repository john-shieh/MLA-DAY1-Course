{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"./../../images/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>\n",
    "    \n",
    "    \n",
    "# <a name=\"0\">MLU Day One Machine Learning - Demo</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[__AutoGluon__](https://auto.gluon.ai/stable/index.html#) automates machine learning tasks enabling you to easily achieve strong predictive performance in your applications with just a few lines of code. \n",
    "\n",
    "This notebook shows how to use AutoGluon Tabular to solve a __multiclass classification task__. The metric we use to evaluate the performance of the model is accuracy.\n",
    "\n",
    "1. <a href=\"#1\">Business Problem and ML Problem Description</a>\n",
    "2. <a href=\"#2\">Importing AutoGluon</a>\n",
    "3. <a href=\"#3\">Getting the Data</a>\n",
    "4. <a href=\"#4\">Sampling Data</a>\n",
    "5. <a href=\"#5\">Model Training with AutoGluon (smaller train dataset)</a>\n",
    "6. <a href=\"#6\">AutoGluon Training Results</a>\n",
    "7. <a href=\"#7\">Model Prediction with AutoGluon</a>\n",
    "8. <a href=\"#8\">Re-Train (with full train data) and predict again</a>\n",
    "9. <a href=\"#9\">Before You Go (clean up model artifacts)</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Jupiter notebooks environment__:\n",
    "\n",
    "* Jupiter notebooks allow creating and sharing documents that contain both code and rich text cells. If you are not familiar with Jupiter notebooks, read more [here](https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html). \n",
    "* This is a quick-start demo to bring you up to speed on coding and experimenting with machine learning. Move through the notebook __from top to bottom__. \n",
    "* Run each code cell to see its output. To run a cell, click within the cell and press __Shift+Enter__, or click __Run__ from the top of the page menu. \n",
    "* A `[*]` symbol next to the cell indicates the code is still running. A `[#]` symbol, where # is an integer, indicates it is finished.\n",
    "* Beware, __some code cells might take longer to run__, sometimes 5-10 minutes (depending on the task, installing packages and libraries, training models, etc.)\n",
    "\n",
    "Let's start by loading some libraries and packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q autogluon==0.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a name=\"1\">Business Problem and ML Problem Description</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "__Business Problem:__ Products from the Amazon Product Catalog cannot be listed for sale because are missing some relevant information, the Unit Of Measure (count, volume, weight). \n",
    "\n",
    "__ML Problem Description:__ Predict the Unit Of Measure (count, volume, weight) Identification (UOMI) for a product from the Amazon Product Catalog. \n",
    "> This is a __multiclass classification__ task (3 distinct classes). <br>\n",
    "\n",
    "The data for this ML problem has 33 features columns and 1 label column. Examples of features include:\n",
    "\n",
    "\n",
    "| Feature | Description |\n",
    "| :---        |    :----  |\n",
    "| marketplace_id | Marketplace ID.|\n",
    "| product_type   | Type of product.  |\n",
    "| item_name | Short item description. |\n",
    "| product_description   | Long item description.  |\n",
    "| bullet_point | Bullet point item description. |\n",
    "| brand   | Brand name.  |\n",
    "| manufacturer | Manufacturer name. |\n",
    "| ...   | ...  |\n",
    "| list_price_value_with_tax   | Price of item including tax.  |\n",
    "| imgID | ID for image of product. |\n",
    "| ID   | Product identifier.  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. <a name=\"2\">Importing AutoGluon</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the libraries needed to work with our Tabular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor, TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. <a name=\"3\">Getting the Data</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's load the datasets and look at a few data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TabularDataset(\"../../data/uomi-train.csv\")\n",
    "test = TabularDataset(\"../../data/uomi-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 28305\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>marketplace_id</th>\n",
       "      <th>label</th>\n",
       "      <th>product_type</th>\n",
       "      <th>item_name</th>\n",
       "      <th>product_description</th>\n",
       "      <th>bullet_point</th>\n",
       "      <th>brand</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>part_number</th>\n",
       "      <th>...</th>\n",
       "      <th>item_dimensions_height</th>\n",
       "      <th>item_dimensions_width</th>\n",
       "      <th>item_dimensions_length</th>\n",
       "      <th>normalized_item_weight</th>\n",
       "      <th>normalized_item_package_weight</th>\n",
       "      <th>list_price_currency</th>\n",
       "      <th>list_price_value</th>\n",
       "      <th>list_price_value_with_tax</th>\n",
       "      <th>imgID</th>\n",
       "      <th>ID_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1633</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>JELL-O Play Ocean Build + Eat Kit, 6 oz Box</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One 6 oz. JELL-O Play Ocean Build + Eat Kit</td>\n",
       "      <td>Jell-O Play</td>\n",
       "      <td>Jell-o</td>\n",
       "      <td>4300008150</td>\n",
       "      <td>...</td>\n",
       "      <td>2.625</td>\n",
       "      <td>6.625</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.500449</td>\n",
       "      <td>USD</td>\n",
       "      <td>3.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51sislDjTYL</td>\n",
       "      <td>9cd726a519754b6bad27be39bc95cac6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18103</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>Crystal Light Pure Variety Pack includes- Rasp...</td>\n",
       "      <td>With no artificial sweeteners, flavors or pres...</td>\n",
       "      <td>Customer Will Receive 6 Boxes Total - 1 Raspbe...</td>\n",
       "      <td>Crystal Light</td>\n",
       "      <td>Crystal Light</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.599657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41MsGCednqL</td>\n",
       "      <td>44a997b7ff9f4d2ebd1615ac5f3861ff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  marketplace_id  label product_type  \\\n",
       "0   1633               1      1      GROCERY   \n",
       "1  18103               1      2      GROCERY   \n",
       "\n",
       "                                           item_name  \\\n",
       "0        JELL-O Play Ocean Build + Eat Kit, 6 oz Box   \n",
       "1  Crystal Light Pure Variety Pack includes- Rasp...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0                                                NaN   \n",
       "1  With no artificial sweeteners, flavors or pres...   \n",
       "\n",
       "                                        bullet_point          brand  \\\n",
       "0        One 6 oz. JELL-O Play Ocean Build + Eat Kit    Jell-O Play   \n",
       "1  Customer Will Receive 6 Boxes Total - 1 Raspbe...  Crystal Light   \n",
       "\n",
       "    manufacturer part_number  ... item_dimensions_height  \\\n",
       "0         Jell-o  4300008150  ...                  2.625   \n",
       "1  Crystal Light         NaN  ...                    NaN   \n",
       "\n",
       "  item_dimensions_width item_dimensions_length normalized_item_weight  \\\n",
       "0                 6.625                    8.5               0.023438   \n",
       "1                   NaN                    NaN                    NaN   \n",
       "\n",
       "  normalized_item_package_weight list_price_currency list_price_value  \\\n",
       "0                       0.500449                 USD             3.99   \n",
       "1                       0.599657                 NaN              NaN   \n",
       "\n",
       "  list_price_value_with_tax        imgID                              ID_0  \n",
       "0                       NaN  51sislDjTYL  9cd726a519754b6bad27be39bc95cac6  \n",
       "1                       NaN  41MsGCednqL  44a997b7ff9f4d2ebd1615ac5f3861ff  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print size of train set\n",
    "print(f\"Size of training set: {len(train)}\")\n",
    "\n",
    "# Show the first rows of train data\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 4. <a name=\"4\">Sampling Data</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "It is good practice to grab a small sample dataset to quickly run AutoGluon before using the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample of 1000 datapoints for a quick test\n",
    "train_sample_small = train.sample(n=1000, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 5. <a name=\"5\">Model Training with AutoGluon</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "\n",
    "We can train a model using AutoGluon with only a single line of code.  All we need to do is tell AutoGluon what column from the dataset we want to predict, and what the train dataset is.\n",
    "\n",
    "For fast experimentation, we use only the small sample from our train dataset, containing 1000 data points.\n",
    "\n",
    "__NOTE__: Training on this smaller dataset might still take approx. 3-4 minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230706_182206/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230706_182206/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Mon Apr 24 23:34:06 UTC 2023\n",
      "Disk Space Avail:   477.39 GB / 528.24 GB (90.4%)\n",
      "Train Data Rows:    1000\n",
      "Train Data Columns: 33\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [2, 0, 1]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31284.46 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.39 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['item_name', 'product_description', 'bullet_point', 'generic_keyword', 'style']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 629\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['marketplace_id', 'list_price_value_with_tax']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 2): ['imgID', 'ID_0']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 2 | ['imgID', 'ID_0']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        :  9 | ['number_of_items', 'case_pack_quantity', 'item_package_quantity', 'item_dimensions_height', 'item_dimensions_width', ...]\n",
      "\t\t('int', [])          :  1 | ['ID']\n",
      "\t\t('object', [])       : 14 | ['product_type', 'brand', 'manufacturer', 'part_number', 'model_number', ...]\n",
      "\t\t('object', ['text']) :  5 | ['item_name', 'product_description', 'bullet_point', 'generic_keyword', 'style']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  13 | ['product_type', 'brand', 'manufacturer', 'part_number', 'model_number', ...]\n",
      "\t\t('category', ['text_as_category'])  :   4 | ['product_description', 'bullet_point', 'generic_keyword', 'style']\n",
      "\t\t('float', [])                       :   9 | ['number_of_items', 'case_pack_quantity', 'item_package_quantity', 'item_dimensions_height', 'item_dimensions_width', ...]\n",
      "\t\t('int', [])                         :   1 | ['ID']\n",
      "\t\t('int', ['binned', 'text_special']) :  94 | ['item_name.char_count', 'item_name.word_count', 'item_name.capital_ratio', 'item_name.lower_ratio', 'item_name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :   1 | ['list_price_currency']\n",
      "\t\t('int', ['text_ngram'])             : 629 | ['__nlp__.10', '__nlp__.100', '__nlp__.12', '__nlp__.15', '__nlp__.16', ...]\n",
      "\t6.4s = Fit runtime\n",
      "\t29 features in original data used to generate 751 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 6.42s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.58\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.61\t = Validation score   (accuracy)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.745\t = Validation score   (accuracy)\n",
      "\t7.28s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.755\t = Validation score   (accuracy)\n",
      "\t1.97s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.78\t = Validation score   (accuracy)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.735\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.725\t = Validation score   (accuracy)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t19.48s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.745\t = Validation score   (accuracy)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.73\t = Validation score   (accuracy)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.765\t = Validation score   (accuracy)\n",
      "\t1.95s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.75\t = Validation score   (accuracy)\n",
      "\t2.57s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.76\t = Validation score   (accuracy)\n",
      "\t5.48s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.825\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 52.32s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230706_182206/\")\n"
     ]
    }
   ],
   "source": [
    "# We specify train and validation data for the model training\n",
    "first_predictor = TabularPredictor(label=\"label\").fit(\n",
    "    train_data=train_sample_small\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 6. <a name=\"6\">AutoGluon Training Results</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Now let's take a look at all the training information AutoGluon provides via its [__leaderboard function__](https://auto.gluon.ai/api/autogluon.task.html?highlight=leaderboard#autogluon.tabular.TabularPredictor.leaderboard). <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.114462</td>\n",
       "      <td>21.056885</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.040112</td>\n",
       "      <td>19.477260</td>\n",
       "      <td>0.040112</td>\n",
       "      <td>19.477260</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.012597</td>\n",
       "      <td>1.798811</td>\n",
       "      <td>0.012597</td>\n",
       "      <td>1.798811</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.013985</td>\n",
       "      <td>1.947053</td>\n",
       "      <td>0.013985</td>\n",
       "      <td>1.947053</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.028222</td>\n",
       "      <td>5.479264</td>\n",
       "      <td>0.028222</td>\n",
       "      <td>5.479264</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>1.971939</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>1.971939</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.054374</td>\n",
       "      <td>2.571996</td>\n",
       "      <td>0.054374</td>\n",
       "      <td>2.571996</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.018688</td>\n",
       "      <td>7.281922</td>\n",
       "      <td>0.018688</td>\n",
       "      <td>7.281922</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.075681</td>\n",
       "      <td>0.765243</td>\n",
       "      <td>0.075681</td>\n",
       "      <td>0.765243</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.077066</td>\n",
       "      <td>0.801487</td>\n",
       "      <td>0.077066</td>\n",
       "      <td>0.801487</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.073627</td>\n",
       "      <td>0.875080</td>\n",
       "      <td>0.073627</td>\n",
       "      <td>0.875080</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.076851</td>\n",
       "      <td>0.781125</td>\n",
       "      <td>0.076851</td>\n",
       "      <td>0.781125</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>0.107069</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>0.107069</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.244875</td>\n",
       "      <td>0.074783</td>\n",
       "      <td>0.244875</td>\n",
       "      <td>0.074783</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val   fit_time  \\\n",
       "0   WeightedEnsemble_L2      0.825       0.114462  21.056885   \n",
       "1              CatBoost      0.820       0.040112  19.477260   \n",
       "2              LightGBM      0.780       0.012597   1.798811   \n",
       "3               XGBoost      0.765       0.013985   1.947053   \n",
       "4         LightGBMLarge      0.760       0.028222   5.479264   \n",
       "5            LightGBMXT      0.755       0.014995   1.971939   \n",
       "6        NeuralNetTorch      0.750       0.054374   2.571996   \n",
       "7       NeuralNetFastAI      0.745       0.018688   7.281922   \n",
       "8        ExtraTreesGini      0.745       0.075681   0.765243   \n",
       "9      RandomForestGini      0.735       0.077066   0.801487   \n",
       "10       ExtraTreesEntr      0.730       0.073627   0.875080   \n",
       "11     RandomForestEntr      0.725       0.076851   0.781125   \n",
       "12       KNeighborsDist      0.610       0.012778   0.107069   \n",
       "13       KNeighborsUnif      0.580       0.244875   0.074783   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000723           0.704545            2       True   \n",
       "1                 0.040112          19.477260            1       True   \n",
       "2                 0.012597           1.798811            1       True   \n",
       "3                 0.013985           1.947053            1       True   \n",
       "4                 0.028222           5.479264            1       True   \n",
       "5                 0.014995           1.971939            1       True   \n",
       "6                 0.054374           2.571996            1       True   \n",
       "7                 0.018688           7.281922            1       True   \n",
       "8                 0.075681           0.765243            1       True   \n",
       "9                 0.077066           0.801487            1       True   \n",
       "10                0.073627           0.875080            1       True   \n",
       "11                0.076851           0.781125            1       True   \n",
       "12                0.012778           0.107069            1       True   \n",
       "13                0.244875           0.074783            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          14  \n",
       "1           8  \n",
       "2           5  \n",
       "3          11  \n",
       "4          13  \n",
       "5           4  \n",
       "6          12  \n",
       "7           3  \n",
       "8           9  \n",
       "9           6  \n",
       "10         10  \n",
       "11          7  \n",
       "12          2  \n",
       "13          1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_predictor.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 7. <a name=\"7\">Model Prediction with AutoGluon</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Now that we trained a model on the train data (that had labels to learn from), let's use the fitted model to predict the labels for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the first 20 data points in the test dataset: [2 2 2 2 2 1 2 1 2 2 1 0 2 2 2 1 0 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "prediction = first_predictor.predict(test)\n",
    "\n",
    "# Print a few test predictions\n",
    "print(f\"Predictions for the first 20 data points in the test dataset: {prediction.values[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 8. <a name=\"8\">Re-Train (with full train data) and predict again</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "This first submission to the MLU Leaderboard using a small sample from the train dataset, might not perform best. To improve performance, repeat the process using the full dataset and submit again to see if the score gets better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230706_182304/\"\n",
      "Beginning AutoGluon training ... Time limit = 1200s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230706_182304/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Mon Apr 24 23:34:06 UTC 2023\n",
      "Disk Space Avail:   477.33 GB / 528.24 GB (90.4%)\n",
      "Train Data Rows:    28305\n",
      "Train Data Columns: 33\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [1, 2, 0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30954.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 69.35 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['item_name', 'product_description', 'bullet_point', 'generic_keyword']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 10000\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['marketplace_id']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ID_0']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['ID_0']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 10 | ['number_of_items', 'case_pack_quantity', 'item_package_quantity', 'item_dimensions_height', 'item_dimensions_width', ...]\n",
      "\t\t('int', [])          :  1 | ['ID']\n",
      "\t\t('object', [])       : 16 | ['product_type', 'brand', 'manufacturer', 'part_number', 'model_number', ...]\n",
      "\t\t('object', ['text']) :  4 | ['item_name', 'product_description', 'bullet_point', 'generic_keyword']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   15 | ['product_type', 'brand', 'manufacturer', 'part_number', 'model_number', ...]\n",
      "\t\t('category', ['text_as_category'])  :    4 | ['item_name', 'product_description', 'bullet_point', 'generic_keyword']\n",
      "\t\t('float', [])                       :   10 | ['number_of_items', 'case_pack_quantity', 'item_package_quantity', 'item_dimensions_height', 'item_dimensions_width', ...]\n",
      "\t\t('int', [])                         :    1 | ['ID']\n",
      "\t\t('int', ['binned', 'text_special']) :   98 | ['item_name.char_count', 'item_name.word_count', 'item_name.capital_ratio', 'item_name.lower_ratio', 'item_name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :    1 | ['list_price_currency']\n",
      "\t\t('int', ['text_ngram'])             : 9527 | ['__nlp__.00', '__nlp__.000', '__nlp__.01', '__nlp__.02', '__nlp__.05', ...]\n",
      "\t81.7s = Fit runtime\n",
      "\t31 features in original data used to generate 9656 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 545.51 MB (1.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 86.76s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.08832361773538244, Train Rows: 25805, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 1113.24s of the 1112.7s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 3.588 GB out of 29.443 GB available memory (60.933%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.66 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\tNot enough memory to train KNeighborsUnif... Skipping this model.\n",
      "Fitting model: KNeighborsDist ... Training model for up to 1107.07s of the 1106.53s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 3.588 GB out of 29.472 GB available memory (60.873%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.66 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\tNot enough memory to train KNeighborsDist... Skipping this model.\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 1100.67s of the 1100.14s of remaining time.\n",
      "No improvement since epoch 2: early stopping\n",
      "\t0.8244\t = Validation score   (accuracy)\n",
      "\t44.86s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 1055.16s of the 1054.62s of remaining time.\n",
      "\t0.866\t = Validation score   (accuracy)\n",
      "\t32.95s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 1021.2s of the 1020.66s of remaining time.\n",
      "\t0.8732\t = Validation score   (accuracy)\n",
      "\t51.81s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 968.25s of the 967.71s of remaining time.\n",
      "\t0.8272\t = Validation score   (accuracy)\n",
      "\t49.82s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 917.42s of the 916.89s of remaining time.\n",
      "\t0.8256\t = Validation score   (accuracy)\n",
      "\t41.83s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 874.6s of the 874.06s of remaining time.\n",
      "\tMany features detected (9656), dynamically setting 'colsample_bylevel' to 0.1035625517812759 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\t0.8616\t = Validation score   (accuracy)\n",
      "\t176.59s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 696.74s of the 696.21s of remaining time.\n",
      "\t0.8156\t = Validation score   (accuracy)\n",
      "\t62.76s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 632.9s of the 632.36s of remaining time.\n",
      "\t0.8144\t = Validation score   (accuracy)\n",
      "\t55.95s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 575.89s of the 575.36s of remaining time.\n",
      "\t0.862\t = Validation score   (accuracy)\n",
      "\t165.68s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 409.2s of the 408.65s of remaining time.\n",
      "\t0.7948\t = Validation score   (accuracy)\n",
      "\t34.4s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 374.13s of the 373.51s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's multi_error: 0.1232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.878\t = Validation score   (accuracy)\n",
      "\t258.15s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 111.77s of remaining time.\n",
      "\t0.88\t = Validation score   (accuracy)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1091.25s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230706_182304/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the first 20 data points in the test dataset: [2 2 2 2 2 1 2 1 2 2 1 0 2 2 2 2 2 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Retrain the model using all training data \n",
    "# We let AutoGluon handle the train/validation split directly\n",
    "# NOTE: We cap the training time to 20 minutes!\n",
    "second_predictor = TabularPredictor(label=\"label\").fit(\n",
    "    train_data=train, time_limit = 60*20) \n",
    "\n",
    "# Use the trained model to make predictions on the test dataset\n",
    "prediction = second_predictor.predict(test)\n",
    "\n",
    "# Print a few test predictions\n",
    "print(f\"Predictions for the first 20 data points in the test dataset: {prediction.values[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 9. <a name=\"10\">Before You Go</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "After you are done with this Demo, clean model artifacts by uncommenting and executing the cell below.\n",
    "\n",
    "__It is always good practice to clean everything when you are done, preventing the disk from getting full.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -r AutogluonModels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
